---
permalink: /W05/
---
[HOME](../)

<br>

# Top 10 List of Week 05

```In this Top 10 list, I will give what materials I have learned during week 5 at my Operating System course. In each of the points I stated, there is a clickable link that will take you to the website I learned the material from, my thoughts and review of the page itself, and a short summary of the material.```

<b>One [What is Virtual Memory and How Does It Work?](https://searchstorage.techtarget.com/definition/virtual-memory)</b>

Virtual memory is a memory management technique where secondary memory can be used as if it were a part of the main memory. Virtual memory is a very common technique used in the operating systems (OS) of computers.

Virtual memory uses hardware and software to allow a computer to compensate for physical memory shortages, by temporarily transferring data from random access memory (RAM) to disk storage. In essence, virtual memory allows a computer to treat secondary memory as though it were the main memory.

Today, most PCs come with up to around 4 GB of RAM. However, sometimes this isn't enough to run all the programs a user might want to use at once. This is where virtual memory comes in. Virtual memory can be used to swap data that has not been used recently -- and move it over to a storage device like a hard drive or solid-state drive (SDD). This will free up more space on the RAM.


<b>Two [Virtual Address Space](https://en.wikipedia.org/wiki/Virtual_address_space)</b>

In computing, a virtual address space (VAS) or address space is the set of ranges of virtual addresses that an operating system makes available to a process. The range of virtual addresses usually starts at a low address and can extend to the highest address allowed by the computer's instruction set architecture and supported by the operating system's pointer size implementation, which can be 4 bytes for 32-bit or 8 bytes for 64-bit OS versions. This provides several benefits, one of which is security through process isolation assuming each process is given a separate address space.

<b>Three [Memory Hierarchy Design and its Characteristics](https://www.geeksforgeeks.org/memory-hierarchy-design-and-its-characteristics/)</b>

In the Computer System Design, Memory Hierarchy is an enhancement to organize the memory such that it can minimize the access time. The Memory Hierarchy was developed based on a program behavior known as locality of references. This Memory Hierarchy Design is divided into 2 main types:

- External Memory or Secondary Memory :
Comprising of Magnetic Disk, Optical Disk, Magnetic Tape i.e. peripheral storage devices which are accessible by the processor via I/O Module.
                                  
- Internal Memory or Primary Memory –
Comprising of Main Memory, Cache Memory & CPU registers. This is directly accessible by the processor.


<b>Four [High-Performance Memory At Low Cost Per Bit](https://semiengineering.com/high-performance-memory-at-low-cost-per-bit/)</b>

Applications demand increasing memory capacity at low cost and high performance. Hybrid memory solutions that combine DRAM with emerging memory offer the optimum cost per performance metric. Smart management is the key to making this architecture successful in meeting market demands.

<b>Five [What is Caching?](https://www.citrix.com/glossary/caching.html#:~:text=Caching%20is%20an%20area%20of,temporarily%20storing%20recently%20used%20information.&text=For%20example%2C%20when%20a%20user,has%20stored%20the%20user's%20activity.)</b>

Caching is an area of a computer’s memory devoted to temporarily storing recently used information. The content, which includes HTML pages, images, files and Web objects, is stored on the local hard drive in order to make it faster for the user to access it, which helps improve the efficiency of the computer and its overall performance.

Most caching occurs without the user knowing about it. For example, when a user returns to a Web page they have recently accessed, the browser can pull those files from the cache instead of the original server because it has stored the user’s activity. The storing of that information saves the user time by getting to it faster, and lessens the traffic on the network.

<b>Six [Differences between Cache Memory and Virtual Memory](https://www.includehelp.com/operating-systems/differences-between-cache-memory-and-virtual-memory.aspx#:~:text=The%20term%20%22virtual%20memory%22%20refers,enlarges%20the%20volume%20of%20RAM.)</b>

Cache Memory :

- Cache memory is a small high-speed memory usually Static RAM (SRAM) that contains the most recently accessed pieces of main memory.

- By using cache Access time consumed by the processor is less as compared to main memory.

- Hardware has the control over cache memory.

- The size of Cache memory is less than virtual memory.

- The cache contains data items that are most frequently used by the processor while the whole program resides in the secondary memory.

Virtual Memory :

- The term "virtual memory" refers to space allocated on a hard disk where data can be stored for fast access.

- Virtual memory enlarges the volume of RAM.

- Operating system has the control over virtual memory.

- The size of virtual memory is more than cache memory.

- In virtual memory, larger programs can be executed while there is a sufficiently small amount of main memory.


<b>Seven [What does it mean to allocate memory?](https://www.techopedia.com/definition/27492/memory-allocation)</b>

Memory allocation is primarily a computer hardware operation but is managed through operating system and software applications. Memory allocation process is quite similar in physical and virtual memory management. Programs and services are assigned with a specific memory as per their requirements when they are executed. Once the program has finished its operation or is idle, the memory is released and allocated to another program or merged within the primary memory.

Memory allocation has two core types;

- Static Memory Allocation: The program is allocated memory at compile time.

- Dynamic Memory Allocation: The programs are allocated with memory at run time.


<b>Eight [What is NUMA (non-uniform memory access)?](https://www.motioncontroltips.com/what-is-non-uniform-memory-access-in-industrial-controls/)</b>

Non-uniform memory access (NUMA) is a kind of memory architecture that allows a processor faster access to contents of memory than other traditional techniques.

In other words, in a NUMA architecture, a processor can access local memory much faster than non-local memory. This is because in a NUMA setup, each processor is assigned a specific local memory exclusively for its own use. This eliminates sharing of non-local memory, reducing delays when multiple requests come in for access to the same memory location.


<b>Nine [Thrashing and Working Sets](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter12/lecture.php?topic=thrashing)</b>

How to deal with thrashing? If a single process is too large for memory, there is nothing the OS can do. That process will simply thrash.
If the problem arises because of the sum of several processes:

- Figure out how much memory each process needs.

- Change scheduling priorities to run processes in groups that fit comfortably in memory: must shed load.

Working Sets: conceptual model proposed by Peter Denning to prevent thrashing. The collection of pages a process is using actively, and which must thus be memory-resident to prevent this process from thrashing. If the sum of all working sets of all runnable threads exceeds the size of memory, then stop running some of the threads for a while. Divide processes into two groups: active and inactive:

- When a process is active its entire working set must always be in memory: never execute a thread whose working set is not resident.

- When a process becomes inactive, its working set can migrate to disk.

- Threads from inactive processes are never scheduled for execution.

- The collection of active processes is called the balance set.

- The system must have a mechanism for gradually moving processes into and out of the balance set.

- As working sets change, the balance set must be adjusted.


<b>Ten [Page Replacement Algorithms in Operating Systems](https://en.wikipedia.org/wiki/Page_replacement_algorithm)</b>

In a computer operating system that uses paging for virtual memory management, page replacement algorithms decide which memory pages to page out, sometimes called swap out, or write to disk, when a page of memory needs to be allocated. Page replacement happens when a requested page is not in memory (page fault) and a free page cannot be used to satisfy the allocation, either because there are none, or because the number of free pages is lower than some threshold.
